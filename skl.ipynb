import pandas as pd
import talib as ta
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import logging
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor,VotingRegressor
from sklearn.metrics import mean_squared_error, r2_score
DataFrame = pd.DataFrame
logging.basicConfig(level=logging.INFO)
def preprocess_data(data:DataFrame):
    # Implement your preprocessing logic here
    # Example: Convert data to lowercase
    # 生成技术指标
    data['SMA'] = data['close'].rolling(window=20).mean()
    data['EMA20'] = data['close'].ewm(span=20, adjust=False).mean()
    data['MACD'] = data['close'].ewm(span=12, adjust=False).mean() - data['close'].ewm(span=26, adjust=False).mean()
    data['Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()
    data['MACD_Histogram'] = data['MACD'] - data['Signal']
    data['RSI'] = ta.RSI(data['close'], timeperiod=14)
    data['UpperBB'],data['MiddleBB'],data['LowerBB'] = ta.BBANDS(data['close'], timeperiod=20)
    data['ATR'] = ta.ATR(data['high'], data['low'], data['close'], timeperiod=14)
    data['Volatility'] = data['ATR'] / data['close']
     # 标准化处理
    # scaler = RobustScaler()
    # scaled_features = scaler.fit_transform(data[features])
    return data.dropna()
def create_features(data:DataFrame, lookahead = 5):
    # 特征工程
    features = data[['RSI', 'MACD', 'Signal', 'EMA20', 'UpperBB', 'MiddleBB', 'LowerBB']]
    for lag in [1, 3, 5]:
        data[f'return_lag{lag}'] = data['close'].pct_change(lag)
    # 添加技术指标交叉信号
    data['MACD_cross'] = np.where(data['MACD'] > data['Signal'], 1, -1)
    data['BB_width'] = (data['UpperBB'] - data['LowerBB']) / data['MiddleBB']
    # 未来收益率
    data['future_return'] = data['close'].pct_change(lookahead).shift(-lookahead)

    data['log_return'] = np.log(data['close']).diff()
    data['volatility_30'] = data['log_return'].rolling(30).std()
    #  # 新增行业相关性特征（示例）
    # data['sector_corr'] = data['close'].rolling(30).corr(other=data['sector_index'])
    # 新增时间序列特征
    data['month'] = data.index.month
    data['day_of_week'] = data.index.dayofweek

    # 特征选择
    selected_features = ['RSI', 'MACD','Signal', 'volatility_30',  'UpperBB', 'MiddleBB', 'LowerBB', 'BB_width',
                        'return_lag1', 'return_lag3', 'month']
    # 确保时间对齐
    data = data.dropna()
    # combined = data[['RSI', 'MACD', 'EMA20', 'future_return'] + 
    #                [col for col in data.columns if 'lag' in col]].dropna()
    return  data[selected_features], data['future_return']

from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV

def train_model_xgb(X, y):
    tscv = TimeSeriesSplit(n_splits=5, test_size=21)
    
    # XGBoost参数网格搜索
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [3, 5],
        'learning_rate': [0.01, 0.1]
    }
    
    # 使用早停法
    xgb = XGBRegressor(objective='reg:squarederror', n_jobs=-1)
    
    grid_search = GridSearchCV(
        estimator=xgb,
        param_grid=param_grid,
        cv=tscv,
        scoring='neg_mean_squared_error'
    )
    
    grid_search.fit(X, y)
    
    return grid_search.best_estimator_
def calculate_threshold(signals):
    rolling_mean = signals.rolling(21).mean()
    rolling_std = signals.rolling(21).std()
    return rolling_mean + rolling_std, rolling_mean - rolling_std
def train_model(X, y):
    """时间序列分割"""
    tscv = TimeSeriesSplit(n_splits=5, test_size=21)
    results = {}
    for fold, (train_index, test_index) in enumerate(tscv.split(X)):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]
        pipeline = Pipeline([
            ('scaler', RobustScaler()),
            ('regressor', RandomForestRegressor(
                n_estimators=200,
                max_depth=8,
                random_state=42
            ))
        ])
        # 训练模型
        pipeline.fit(X_train, y_train)
        results[fold] = {
            "model": pipeline,
            "test_index": test_index,
            "train_score": pipeline.score(X_train, y_train),
            "test_score": pipeline.score(X_test, y_test)
        }
    """Train R2 和 Test R2: 这些值指的是模型在训练集和测试集上的决定系数（R平方）。
    R平方是一个统计量，用来表示模型对数据的拟合程度，其值范围从负无穷到1。一个R平方值越接近于1，
    意味着模型解释了更多的方差，拟合效果越好。然而，如果R平方过高（尤其是训练集上），可能也暗示着过拟合的风险。"""
    return results
def walk_forward_validation(data, train_size=252, test_size=21):
    results = []
    for i in range(len(data) - train_size - test_size):
        train = data[i:i+train_size]
        test = data[i+train_size:i+train_size+test_size]
        model = train_model(train)
        preds = model.predict(test)
        # results.append(evaluate(preds, test['actual']))
    return results
def backtest(results, X, y, initial_capital=100000):
    all_preds = []
    all_dates = []
    for fold in results:
        model = results[fold]["model"]
         # 获取该fold的测试集索引（需在训练时保存）
        test_index = results[fold]["test_index"]  # 新增test_index保存
        # 确保输入为DataFrame
        X_test = X.iloc[test_index].to_frame().T if isinstance(X.iloc[test_index], pd.Series) else X.iloc[test_index]
        # test_index = model.named_steps['regressor'].feature_importances_.argmax()  # 获取重要特征
        preds = model.predict(X_test)
        all_preds.extend(preds)
        all_dates.extend(X.iloc[test_index].index)
    # 生成预测信号
    logging.info(f"Backtesting on {len(all_preds)} predictions")
    signals = pd.Series(all_preds, index=all_dates).sort_index().rolling(5).mean()  # 5日平滑信号
    #使用滚动分位数确定阈值
    signals = signals.rolling(window=21).apply(
        lambda x: (x[-1] - x.mean()) / x.std()
    )
    # 对齐目标变量
    aligned_y = y.reindex(signals.index)
    # 信号生成（添加容错机制）
    valid_signals = signals.dropna()
    signals = np.where(valid_signals > 0.015, 1, 
                      np.where(valid_signals < -0.015, -1, 0))
    # 计算交易次数
    trade_count = np.abs(np.diff(valid_signals , prepend=0)).sum()

    transaction_cost = trade_count * 0.0005  # 假设0.05%交易成本
    # 计算策略收益
    returns = aligned_y.iloc[:len(signals)].values * signals - transaction_cost

    cumulative_returns = pd.Series(
        (1 + returns).cumprod(), 
        index=aligned_y.iloc[:len(signals)].index
    )
    
    # 基准收益（买入持有）
    # 基准收益计算修正
    benchmark = (1 + y.reindex(cumulative_returns.index)).cumprod()
    
    # 回测指标 Sharpe Ratio (夏普比率)
    """夏普比率是用来衡量每单位总风险获得的超额回报率的指标。它帮助投资者了解他们是否因承担额外风险而获得了相应的回报。
    夏普比率为正且越高越好，说明该投资相对于其风险提供了更好的回报。"""
    sharpe_ratio = np.sqrt(252) * returns.mean() / returns.std()
    # 回测指标 Max Drawdown (最大回撤)
    """最大回撤是指在某个时间段内，从最高点开始到最低点结束的最大损失。
    它衡量了投资者在某个时间段内的最大损失率。它是衡量投资风险的一个重要指标，显示了投资期间可能出现的最大资金缩水比例。"""
    max_drawdown = (cumulative_returns / cumulative_returns.cummax() - 1).min()
    


    return cumulative_returns, benchmark, sharpe_ratio, max_drawdown
# 可视化模块
def visualize_results(cumulative, benchmark):
    plt.figure(figsize=(12,6))
    cumulative.plot(label='Strategy')
    benchmark.plot(label='Buy & Hold')
    plt.title('Strategy vs Benchmark Performance')
    plt.xlabel('Date')
    plt.ylabel('Return')
    plt.legend()
    plt.show()
# 模型部署模块
def deploy_model(results, model_name='stock_predictor.pkl'):
    ensemble = VotingRegressor(
        [(f'model_{k}', v['model']) for k, v in results.items()]
    )
    joblib.dump(ensemble, model_name)
if __name__ == '__main__':
    data = pd.read_csv('stock.csv', index_col='date',parse_dates=True)
    data = preprocess_data(data)
    data = data.sort_values(by='date', ascending=True)
    features, target = create_features(data)

    assert len(features) == len(target), f"特征数{len(features)}≠目标数{len(target)}"
    print(f"特征形状: {features.shape}, 目标形状: {target.shape}")
    cv_results = train_model(features, target)
    r = train_model_xgb(features, target)
    print(f"train_model_xgb: {r}")

    # 显示交叉验证结果
    for fold in cv_results:
        print(f"Fold {fold}: Train R2={cv_results[fold]['train_score']:.3f}, Test R2={cv_results[fold]['test_score']:.3f}")
    
    # 集成回测
    cumulative_returns, benchmark, sharpe, drawdown = backtest(cv_results, features, target)
    
    # 可视化
    visualize_results(cumulative_returns, benchmark)
    
    # 部署集成模型
    deploy_model(cv_results)
